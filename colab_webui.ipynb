{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuanyork/CS-Xmind-Note/blob/master/colab_webui.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "环境配置 environment"
      ],
      "metadata": {
        "id": "_o6a8GS2lWQM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9b7iFV3dm1f",
        "outputId": "08bb5c47-9018-4b63-cdd6-425382edba59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q condacolab\n",
        "# Setting up condacolab and installing packages\n",
        "import condacolab\n",
        "condacolab.install_from_url(\"https://repo.anaconda.com/miniconda/Miniconda3-py39_23.11.0-2-Linux-x86_64.sh\")\n",
        "%cd -q /content\n",
        "!git clone https://github.com/RVC-Boss/GPT-SoVITS\n",
        "!conda install -y -q -c pytorch -c nvidia cudatoolkit\n",
        "%cd -q /content/GPT-SoVITS\n",
        "!conda install -y -q -c conda-forge gcc gxx ffmpeg cmake -c pytorch -c nvidia\n",
        "!/usr/local/bin/pip install -r requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://repo.anaconda.com/miniconda/Miniconda3-py39_23.11.0-2-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:23\n",
            "🔁 Restarting kernel...\n",
            "Cloning into 'GPT-SoVITS'...\n",
            "remote: Enumerating objects: 3970, done.\u001b[K\n",
            "remote: Total 3970 (delta 0), reused 0 (delta 0), pack-reused 3970 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3970/3970), 11.26 MiB | 9.36 MiB/s, done.\n",
            "Resolving deltas: 100% (2351/2351), done.\n",
            "Channels:\n",
            " - pytorch\n",
            " - nvidia\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cudatoolkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    archspec-0.2.3             |     pyhd3eb1b0_0          47 KB\n",
            "    ca-certificates-2024.11.26 |       h06a4308_0         131 KB\n",
            "    certifi-2024.8.30          |   py39h06a4308_0         162 KB\n",
            "    conda-24.11.0              |   py39h06a4308_0         934 KB\n",
            "    cudatoolkit-11.7.0         |      hd8887f6_10       831.6 MB  nvidia\n",
            "    frozendict-2.4.2           |   py39h5eee18b_0          55 KB\n",
            "    openssl-3.0.15             |       h5eee18b_0         5.2 MB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       838.1 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  cudatoolkit        nvidia/linux-64::cudatoolkit-11.7.0-hd8887f6_10 \n",
            "  frozendict         pkgs/main/linux-64::frozendict-2.4.2-py39h5eee18b_0 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  archspec                               0.2.1-pyhd3eb1b0_0 --> 0.2.3-pyhd3eb1b0_0 \n",
            "  ca-certificates                     2023.12.12-h06a4308_0 --> 2024.11.26-h06a4308_0 \n",
            "  certifi                         2023.11.17-py39h06a4308_0 --> 2024.8.30-py39h06a4308_0 \n",
            "  conda                              23.11.0-py39h06a4308_0 --> 24.11.0-py39h06a4308_0 \n",
            "  openssl                                 3.0.12-h7f8727e_0 --> 3.0.15-h5eee18b_0 \n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
            "\n",
            "done\n",
            "/usr/local/lib/python3.9/site-packages/conda/base/context.py:200: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
            "\n",
            "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
            "\n",
            "  conda config --add channels defaults\n",
            "\n",
            "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
            "\n",
            "  deprecated.topic(\n",
            "/usr/local/lib/python3.9/site-packages/conda/base/context.py:200: FutureWarning: Adding 'defaults' to channel list implicitly is deprecated and will be removed in 25.3. \n",
            "\n",
            "To remove this warning, please choose a default channel explicitly with conda's regular configuration system, e.g. by adding 'defaults' to the list of channels:\n",
            "\n",
            "  conda config --add channels defaults\n",
            "\n",
            "For more information see https://docs.conda.io/projects/conda/en/stable/user-guide/configuration/use-condarc.html\n",
            "\n",
            "  deprecated.topic(\n",
            "Channels:\n",
            " - conda-forge\n",
            " - pytorch\n",
            " - nvidia\n",
            " - defaults\n",
            "Platform: linux-64\n",
            "Collecting package metadata (repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - cmake\n",
            "    - ffmpeg\n",
            "    - gcc\n",
            "    - gxx\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    _libgcc_mutex-0.1          |      conda_forge           3 KB  conda-forge\n",
            "    _openmp_mutex-4.5          |            2_gnu          23 KB  conda-forge\n",
            "    aom-3.9.1                  |       hac33072_0         2.6 MB  conda-forge\n",
            "    binutils_impl_linux-64-2.43|       h4bf12b8_2         5.4 MB  conda-forge\n",
            "    cairo-1.18.0               |       h3faef2a_0         959 KB  conda-forge\n",
            "    certifi-2024.8.30          |     pyhd8ed1ab_0         160 KB  conda-forge\n",
            "    cmake-3.29.4               |       h91dbaaa_0        18.1 MB  conda-forge\n",
            "    dav1d-1.2.1                |       hd590300_0         742 KB  conda-forge\n",
            "    expat-2.6.4                |       h5888daf_0         135 KB  conda-forge\n",
            "    ffmpeg-7.0.1               | gpl_hb399a10_100         9.6 MB  conda-forge\n",
            "    font-ttf-dejavu-sans-mono-2.37|       hab24e00_0         388 KB  conda-forge\n",
            "    font-ttf-inconsolata-3.000 |       h77eed37_0          94 KB  conda-forge\n",
            "    font-ttf-source-code-pro-2.038|       h77eed37_0         684 KB  conda-forge\n",
            "    font-ttf-ubuntu-0.83       |       h77eed37_3         1.5 MB  conda-forge\n",
            "    fontconfig-2.14.2          |       h14ed4e7_0         266 KB  conda-forge\n",
            "    fonts-conda-ecosystem-1    |                0           4 KB  conda-forge\n",
            "    fonts-conda-forge-1        |                0           4 KB  conda-forge\n",
            "    freetype-2.12.1            |       h267a509_2         620 KB  conda-forge\n",
            "    fribidi-1.0.10             |       h36c2ea0_0         112 KB  conda-forge\n",
            "    gcc-14.2.0                 |       h96c4ede_1          54 KB  conda-forge\n",
            "    gcc_impl_linux-64-14.2.0   |       h6b349bd_1        69.1 MB  conda-forge\n",
            "    gettext-0.22.5             |       he02047a_3         468 KB  conda-forge\n",
            "    gettext-tools-0.22.5       |       he02047a_3         2.6 MB  conda-forge\n",
            "    gmp-6.3.0                  |       hac33072_2         449 KB  conda-forge\n",
            "    gnutls-3.7.9               |       hb077bed_0         1.9 MB  conda-forge\n",
            "    graphite2-1.3.13           |    h59595ed_1003          95 KB  conda-forge\n",
            "    gxx-14.2.0                 |       h96c4ede_1          54 KB  conda-forge\n",
            "    gxx_impl_linux-64-14.2.0   |       h2c03514_1        13.7 MB  conda-forge\n",
            "    harfbuzz-8.5.0             |       hfac3d4d_0         1.5 MB  conda-forge\n",
            "    icu-73.2                   |       h59595ed_0        11.5 MB  conda-forge\n",
            "    kernel-headers_linux-64-3.10.0|      he073ed8_18         921 KB  conda-forge\n",
            "    lame-3.100                 |    h166bdaf_1003         496 KB  conda-forge\n",
            "    ld_impl_linux-64-2.43      |       h712a8e2_2         654 KB  conda-forge\n",
            "    libabseil-20240116.2       | cxx17_he02047a_1         1.2 MB  conda-forge\n",
            "    libarchive-3.7.4           |       hfca40fe_0         851 KB  conda-forge\n",
            "    libasprintf-0.22.5         |       he8f35ee_3          42 KB  conda-forge\n",
            "    libasprintf-devel-0.22.5   |       he8f35ee_3          33 KB  conda-forge\n",
            "    libass-0.17.1              |       h8fe9dca_1         124 KB  conda-forge\n",
            "    libcurl-8.9.1              |       h251f7ec_0         439 KB\n",
            "    libdrm-2.4.123             |       hb9d3cd8_0         296 KB  conda-forge\n",
            "    libexpat-2.6.4             |       h5888daf_0          72 KB  conda-forge\n",
            "    libgcc-14.2.0              |       h77fa898_1         829 KB  conda-forge\n",
            "    libgcc-devel_linux-64-14.2.0|     h41c2201_101         2.6 MB  conda-forge\n",
            "    libgcc-ng-14.2.0           |       h69a702a_1          53 KB  conda-forge\n",
            "    libgettextpo-0.22.5        |       he02047a_3         167 KB  conda-forge\n",
            "    libgettextpo-devel-0.22.5  |       he02047a_3          36 KB  conda-forge\n",
            "    libglib-2.80.2             |       hf974151_0         3.7 MB  conda-forge\n",
            "    libgomp-14.2.0             |       h77fa898_1         450 KB  conda-forge\n",
            "    libhwloc-2.11.2            |default_he43201b_1000         2.3 MB  conda-forge\n",
            "    libiconv-1.17              |       hd590300_2         689 KB  conda-forge\n",
            "    libidn2-2.3.7              |       hd590300_0         124 KB  conda-forge\n",
            "    libmamba-1.5.8             |       hfe524e5_3         1.8 MB\n",
            "    libmambapy-1.5.8           |   py39h2dafd23_3         333 KB\n",
            "    libopenvino-2024.1.0       |       h2da1b83_7         4.9 MB  conda-forge\n",
            "    libopenvino-auto-batch-plugin-2024.1.0|       hb045406_7         107 KB  conda-forge\n",
            "    libopenvino-auto-plugin-2024.1.0|       hb045406_7         224 KB  conda-forge\n",
            "    libopenvino-hetero-plugin-2024.1.0|       h5c03a75_7         187 KB  conda-forge\n",
            "    libopenvino-intel-cpu-plugin-2024.1.0|       h2da1b83_7        10.4 MB  conda-forge\n",
            "    libopenvino-intel-gpu-plugin-2024.1.0|       h2da1b83_7         8.1 MB  conda-forge\n",
            "    libopenvino-intel-npu-plugin-2024.1.0|       he02047a_7         318 KB  conda-forge\n",
            "    libopenvino-ir-frontend-2024.1.0|       h5c03a75_7         196 KB  conda-forge\n",
            "    libopenvino-onnx-frontend-2024.1.0|       h07e8aee_7         1.5 MB  conda-forge\n",
            "    libopenvino-paddle-frontend-2024.1.0|       h07e8aee_7         683 KB  conda-forge\n",
            "    libopenvino-pytorch-frontend-2024.1.0|       he02047a_7         1.1 MB  conda-forge\n",
            "    libopenvino-tensorflow-frontend-2024.1.0|       h39126c6_7         1.3 MB  conda-forge\n",
            "    libopenvino-tensorflow-lite-frontend-2024.1.0|       he02047a_7         476 KB  conda-forge\n",
            "    libopus-1.3.1              |       h7f98852_1         255 KB  conda-forge\n",
            "    libpciaccess-0.18          |       hd590300_0          28 KB  conda-forge\n",
            "    libpng-1.6.43              |       h2797004_0         281 KB  conda-forge\n",
            "    libprotobuf-4.25.3         |       h08a7969_0         2.7 MB  conda-forge\n",
            "    libsanitizer-14.2.0        |       h2a3dede_1         4.3 MB  conda-forge\n",
            "    libsolv-0.7.29             |       ha6fb4c9_0         460 KB  conda-forge\n",
            "    libstdcxx-14.2.0           |       hc0a3c3a_1         3.7 MB  conda-forge\n",
            "    libstdcxx-devel_linux-64-14.2.0|     h41c2201_101        12.9 MB  conda-forge\n",
            "    libstdcxx-ng-14.2.0        |       h4852527_1          53 KB  conda-forge\n",
            "    libtasn1-4.19.0            |       h166bdaf_0         114 KB  conda-forge\n",
            "    libunistring-0.9.10        |       h7f98852_0         1.4 MB  conda-forge\n",
            "    libuuid-2.38.1             |       h0b41bf4_0          33 KB  conda-forge\n",
            "    libuv-1.49.2               |       hb9d3cd8_0         864 KB  conda-forge\n",
            "    libva-2.21.0               |       h4ab18f5_2         185 KB  conda-forge\n",
            "    libvpx-1.14.1              |       hac33072_0         999 KB  conda-forge\n",
            "    libxcb-1.15                |       h0b41bf4_0         375 KB  conda-forge\n",
            "    libxml2-2.12.7             |       hc051c1a_1         688 KB  conda-forge\n",
            "    libzlib-1.2.13             |       h4ab18f5_6          60 KB  conda-forge\n",
            "    lzo-2.10                   |    hd590300_1001         167 KB  conda-forge\n",
            "    ncurses-6.5                |       he02047a_1         868 KB  conda-forge\n",
            "    nettle-3.9.1               |       h7ab15ed_0         988 KB  conda-forge\n",
            "    ocl-icd-2.3.2              |       hb9d3cd8_2          93 KB  conda-forge\n",
            "    opencl-headers-2024.10.24  |       h5888daf_0          53 KB  conda-forge\n",
            "    openh264-2.4.1             |       h59595ed_0         718 KB  conda-forge\n",
            "    openssl-3.4.0              |       hb9d3cd8_0         2.8 MB  conda-forge\n",
            "    p11-kit-0.24.1             |       hc5aa10d_0         4.5 MB  conda-forge\n",
            "    pcre2-10.43                |       hcad00b1_0         929 KB  conda-forge\n",
            "    pixman-0.43.2              |       h59595ed_0         378 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    hb9d3cd8_1002           8 KB  conda-forge\n",
            "    pugixml-1.14               |       h59595ed_0         112 KB  conda-forge\n",
            "    rhash-1.4.5                |       hb9d3cd8_0         183 KB  conda-forge\n",
            "    snappy-1.2.1               |       ha2e4443_0          41 KB  conda-forge\n",
            "    svt-av1-2.1.0              |       hac33072_0         2.5 MB  conda-forge\n",
            "    sysroot_linux-64-2.17      |      h4a8ded7_18        14.8 MB  conda-forge\n",
            "    tbb-2022.0.0               |       hceb3a55_0         174 KB  conda-forge\n",
            "    x264-1!164.3095            |       h166bdaf_2         877 KB  conda-forge\n",
            "    x265-3.5                   |       h924138e_3         3.2 MB  conda-forge\n",
            "    xorg-fixesproto-5.0        |    hb9d3cd8_1003          11 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    hb9d3cd8_1003          30 KB  conda-forge\n",
            "    xorg-libice-1.1.1          |       hb9d3cd8_1          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.4           |       he73a12e_1          27 KB  conda-forge\n",
            "    xorg-libx11-1.8.9          |       h8ee46fc_0         809 KB  conda-forge\n",
            "    xorg-libxau-1.0.11         |       hb9d3cd8_1          14 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.5        |       hb9d3cd8_0          19 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h0b41bf4_2          49 KB  conda-forge\n",
            "    xorg-libxfixes-5.0.3       |    h7f98852_1004          18 KB  conda-forge\n",
            "    xorg-libxrender-0.9.11     |       hd590300_0          37 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    hb9d3cd8_1003          12 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    hb9d3cd8_1004          30 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    hb9d3cd8_1008          72 KB  conda-forge\n",
            "    zlib-1.2.13                |       h4ab18f5_6          91 KB  conda-forge\n",
            "    zstd-1.5.6                 |       ha6fb4c9_0         542 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       254.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  aom                conda-forge/linux-64::aom-3.9.1-hac33072_0 \n",
            "  binutils_impl_lin~ conda-forge/linux-64::binutils_impl_linux-64-2.43-h4bf12b8_2 \n",
            "  cairo              conda-forge/linux-64::cairo-1.18.0-h3faef2a_0 \n",
            "  cmake              conda-forge/linux-64::cmake-3.29.4-h91dbaaa_0 \n",
            "  dav1d              conda-forge/linux-64::dav1d-1.2.1-hd590300_0 \n",
            "  expat              conda-forge/linux-64::expat-2.6.4-h5888daf_0 \n",
            "  ffmpeg             conda-forge/linux-64::ffmpeg-7.0.1-gpl_hb399a10_100 \n",
            "  font-ttf-dejavu-s~ conda-forge/noarch::font-ttf-dejavu-sans-mono-2.37-hab24e00_0 \n",
            "  font-ttf-inconsol~ conda-forge/noarch::font-ttf-inconsolata-3.000-h77eed37_0 \n",
            "  font-ttf-source-c~ conda-forge/noarch::font-ttf-source-code-pro-2.038-h77eed37_0 \n",
            "  font-ttf-ubuntu    conda-forge/noarch::font-ttf-ubuntu-0.83-h77eed37_3 \n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.14.2-h14ed4e7_0 \n",
            "  fonts-conda-ecosy~ conda-forge/noarch::fonts-conda-ecosystem-1-0 \n",
            "  fonts-conda-forge  conda-forge/noarch::fonts-conda-forge-1-0 \n",
            "  freetype           conda-forge/linux-64::freetype-2.12.1-h267a509_2 \n",
            "  fribidi            conda-forge/linux-64::fribidi-1.0.10-h36c2ea0_0 \n",
            "  gcc                conda-forge/linux-64::gcc-14.2.0-h96c4ede_1 \n",
            "  gcc_impl_linux-64  conda-forge/linux-64::gcc_impl_linux-64-14.2.0-h6b349bd_1 \n",
            "  gettext            conda-forge/linux-64::gettext-0.22.5-he02047a_3 \n",
            "  gettext-tools      conda-forge/linux-64::gettext-tools-0.22.5-he02047a_3 \n",
            "  gmp                conda-forge/linux-64::gmp-6.3.0-hac33072_2 \n",
            "  gnutls             conda-forge/linux-64::gnutls-3.7.9-hb077bed_0 \n",
            "  graphite2          conda-forge/linux-64::graphite2-1.3.13-h59595ed_1003 \n",
            "  gxx                conda-forge/linux-64::gxx-14.2.0-h96c4ede_1 \n",
            "  gxx_impl_linux-64  conda-forge/linux-64::gxx_impl_linux-64-14.2.0-h2c03514_1 \n",
            "  harfbuzz           conda-forge/linux-64::harfbuzz-8.5.0-hfac3d4d_0 \n",
            "  kernel-headers_li~ conda-forge/noarch::kernel-headers_linux-64-3.10.0-he073ed8_18 \n",
            "  lame               conda-forge/linux-64::lame-3.100-h166bdaf_1003 \n",
            "  libabseil          conda-forge/linux-64::libabseil-20240116.2-cxx17_he02047a_1 \n",
            "  libasprintf        conda-forge/linux-64::libasprintf-0.22.5-he8f35ee_3 \n",
            "  libasprintf-devel  conda-forge/linux-64::libasprintf-devel-0.22.5-he8f35ee_3 \n",
            "  libass             conda-forge/linux-64::libass-0.17.1-h8fe9dca_1 \n",
            "  libdrm             conda-forge/linux-64::libdrm-2.4.123-hb9d3cd8_0 \n",
            "  libexpat           conda-forge/linux-64::libexpat-2.6.4-h5888daf_0 \n",
            "  libgcc             conda-forge/linux-64::libgcc-14.2.0-h77fa898_1 \n",
            "  libgcc-devel_linu~ conda-forge/noarch::libgcc-devel_linux-64-14.2.0-h41c2201_101 \n",
            "  libgettextpo       conda-forge/linux-64::libgettextpo-0.22.5-he02047a_3 \n",
            "  libgettextpo-devel conda-forge/linux-64::libgettextpo-devel-0.22.5-he02047a_3 \n",
            "  libglib            conda-forge/linux-64::libglib-2.80.2-hf974151_0 \n",
            "  libhwloc           conda-forge/linux-64::libhwloc-2.11.2-default_he43201b_1000 \n",
            "  libiconv           conda-forge/linux-64::libiconv-1.17-hd590300_2 \n",
            "  libidn2            conda-forge/linux-64::libidn2-2.3.7-hd590300_0 \n",
            "  libopenvino        conda-forge/linux-64::libopenvino-2024.1.0-h2da1b83_7 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-batch-plugin-2024.1.0-hb045406_7 \n",
            "  libopenvino-auto-~ conda-forge/linux-64::libopenvino-auto-plugin-2024.1.0-hb045406_7 \n",
            "  libopenvino-heter~ conda-forge/linux-64::libopenvino-hetero-plugin-2024.1.0-h5c03a75_7 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-cpu-plugin-2024.1.0-h2da1b83_7 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-gpu-plugin-2024.1.0-h2da1b83_7 \n",
            "  libopenvino-intel~ conda-forge/linux-64::libopenvino-intel-npu-plugin-2024.1.0-he02047a_7 \n",
            "  libopenvino-ir-fr~ conda-forge/linux-64::libopenvino-ir-frontend-2024.1.0-h5c03a75_7 \n",
            "  libopenvino-onnx-~ conda-forge/linux-64::libopenvino-onnx-frontend-2024.1.0-h07e8aee_7 \n",
            "  libopenvino-paddl~ conda-forge/linux-64::libopenvino-paddle-frontend-2024.1.0-h07e8aee_7 \n",
            "  libopenvino-pytor~ conda-forge/linux-64::libopenvino-pytorch-frontend-2024.1.0-he02047a_7 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-frontend-2024.1.0-h39126c6_7 \n",
            "  libopenvino-tenso~ conda-forge/linux-64::libopenvino-tensorflow-lite-frontend-2024.1.0-he02047a_7 \n",
            "  libopus            conda-forge/linux-64::libopus-1.3.1-h7f98852_1 \n",
            "  libpciaccess       conda-forge/linux-64::libpciaccess-0.18-hd590300_0 \n",
            "  libpng             conda-forge/linux-64::libpng-1.6.43-h2797004_0 \n",
            "  libprotobuf        conda-forge/linux-64::libprotobuf-4.25.3-h08a7969_0 \n",
            "  libsanitizer       conda-forge/linux-64::libsanitizer-14.2.0-h2a3dede_1 \n",
            "  libstdcxx          conda-forge/linux-64::libstdcxx-14.2.0-hc0a3c3a_1 \n",
            "  libstdcxx-devel_l~ conda-forge/noarch::libstdcxx-devel_linux-64-14.2.0-h41c2201_101 \n",
            "  libtasn1           conda-forge/linux-64::libtasn1-4.19.0-h166bdaf_0 \n",
            "  libunistring       conda-forge/linux-64::libunistring-0.9.10-h7f98852_0 \n",
            "  libuuid            conda-forge/linux-64::libuuid-2.38.1-h0b41bf4_0 \n",
            "  libuv              conda-forge/linux-64::libuv-1.49.2-hb9d3cd8_0 \n",
            "  libva              conda-forge/linux-64::libva-2.21.0-h4ab18f5_2 \n",
            "  libvpx             conda-forge/linux-64::libvpx-1.14.1-hac33072_0 \n",
            "  libxcb             conda-forge/linux-64::libxcb-1.15-h0b41bf4_0 \n",
            "  libzlib            conda-forge/linux-64::libzlib-1.2.13-h4ab18f5_6 \n",
            "  lzo                conda-forge/linux-64::lzo-2.10-hd590300_1001 \n",
            "  nettle             conda-forge/linux-64::nettle-3.9.1-h7ab15ed_0 \n",
            "  ocl-icd            conda-forge/linux-64::ocl-icd-2.3.2-hb9d3cd8_2 \n",
            "  opencl-headers     conda-forge/linux-64::opencl-headers-2024.10.24-h5888daf_0 \n",
            "  openh264           conda-forge/linux-64::openh264-2.4.1-h59595ed_0 \n",
            "  p11-kit            conda-forge/linux-64::p11-kit-0.24.1-hc5aa10d_0 \n",
            "  pixman             conda-forge/linux-64::pixman-0.43.2-h59595ed_0 \n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-hb9d3cd8_1002 \n",
            "  pugixml            conda-forge/linux-64::pugixml-1.14-h59595ed_0 \n",
            "  rhash              conda-forge/linux-64::rhash-1.4.5-hb9d3cd8_0 \n",
            "  snappy             conda-forge/linux-64::snappy-1.2.1-ha2e4443_0 \n",
            "  svt-av1            conda-forge/linux-64::svt-av1-2.1.0-hac33072_0 \n",
            "  sysroot_linux-64   conda-forge/noarch::sysroot_linux-64-2.17-h4a8ded7_18 \n",
            "  tbb                conda-forge/linux-64::tbb-2022.0.0-hceb3a55_0 \n",
            "  x264               conda-forge/linux-64::x264-1!164.3095-h166bdaf_2 \n",
            "  x265               conda-forge/linux-64::x265-3.5-h924138e_3 \n",
            "  xorg-fixesproto    conda-forge/linux-64::xorg-fixesproto-5.0-hb9d3cd8_1003 \n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-hb9d3cd8_1003 \n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.1.1-hb9d3cd8_1 \n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.4-he73a12e_1 \n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.8.9-h8ee46fc_0 \n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.11-hb9d3cd8_1 \n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.5-hb9d3cd8_0 \n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h0b41bf4_2 \n",
            "  xorg-libxfixes     conda-forge/linux-64::xorg-libxfixes-5.0.3-h7f98852_1004 \n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.11-hd590300_0 \n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-hb9d3cd8_1003 \n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-hb9d3cd8_1004 \n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-hb9d3cd8_1008 \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  icu                        pkgs/main::icu-73.1-h6a678d5_0 --> conda-forge::icu-73.2-h59595ed_0 \n",
            "  ld_impl_linux-64   pkgs/main::ld_impl_linux-64-2.38-h118~ --> conda-forge::ld_impl_linux-64-2.43-h712a8e2_2 \n",
            "  libarchive         pkgs/main::libarchive-3.6.2-h6ac8c49_2 --> conda-forge::libarchive-3.7.4-hfca40fe_0 \n",
            "  libcurl                                  8.4.0-h251f7ec_1 --> 8.9.1-h251f7ec_0 \n",
            "  libgcc-ng          pkgs/main::libgcc-ng-11.2.0-h1234567_1 --> conda-forge::libgcc-ng-14.2.0-h69a702a_1 \n",
            "  libgomp              pkgs/main::libgomp-11.2.0-h1234567_1 --> conda-forge::libgomp-14.2.0-h77fa898_1 \n",
            "  libmamba                                 1.5.3-haf1ee3a_0 --> 1.5.8-hfe524e5_3 \n",
            "  libmambapy                           1.5.3-py39h2dafd23_0 --> 1.5.8-py39h2dafd23_3 \n",
            "  libsolv              pkgs/main::libsolv-0.7.24-he621ea3_0 --> conda-forge::libsolv-0.7.29-ha6fb4c9_0 \n",
            "  libstdcxx-ng       pkgs/main::libstdcxx-ng-11.2.0-h12345~ --> conda-forge::libstdcxx-ng-14.2.0-h4852527_1 \n",
            "  libxml2              pkgs/main::libxml2-2.10.4-hf1b16e4_1 --> conda-forge::libxml2-2.12.7-hc051c1a_1 \n",
            "  ncurses                 pkgs/main::ncurses-6.4-h6a678d5_0 --> conda-forge::ncurses-6.5-he02047a_1 \n",
            "  openssl              pkgs/main::openssl-3.0.15-h5eee18b_0 --> conda-forge::openssl-3.4.0-hb9d3cd8_0 \n",
            "  pcre2                   pkgs/main::pcre2-10.42-hebb0a14_0 --> conda-forge::pcre2-10.43-hcad00b1_0 \n",
            "  zlib                    pkgs/main::zlib-1.2.13-h5eee18b_0 --> conda-forge::zlib-1.2.13-h4ab18f5_6 \n",
            "  zstd                     pkgs/main::zstd-1.5.5-hc292b87_0 --> conda-forge::zstd-1.5.6-ha6fb4c9_0 \n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  _libgcc_mutex           pkgs/main::_libgcc_mutex-0.1-main --> conda-forge::_libgcc_mutex-0.1-conda_forge \n",
            "  _openmp_mutex          pkgs/main::_openmp_mutex-5.1-1_gnu --> conda-forge::_openmp_mutex-4.5-2_gnu \n",
            "  certifi            pkgs/main/linux-64::certifi-2024.8.30~ --> conda-forge/noarch::certifi-2024.8.30-pyhd8ed1ab_0 \n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Ignoring onnxruntime: markers 'sys_platform == \"darwin\"' don't match your environment\n",
            "Ignoring opencc: markers 'sys_platform != \"linux\"' don't match your environment\n",
            "Collecting numpy==1.23.4 (from -r requirements.txt (line 1))\n",
            "  Downloading numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Collecting scipy (from -r requirements.txt (line 2))\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard (from -r requirements.txt (line 3))\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting librosa==0.9.2 (from -r requirements.txt (line 4))\n",
            "  Downloading librosa-0.9.2-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting numba==0.56.4 (from -r requirements.txt (line 5))\n",
            "  Downloading numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
            "Collecting pytorch-lightning (from -r requirements.txt (line 6))\n",
            "  Downloading pytorch_lightning-2.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting gradio<=4.24.0,>=4.0 (from -r requirements.txt (line 7))\n",
            "  Downloading gradio-4.24.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting ffmpeg-python (from -r requirements.txt (line 8))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting onnxruntime-gpu (from -r requirements.txt (line 10))\n",
            "  Downloading onnxruntime_gpu-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (4.65.0)\n",
            "Collecting funasr==1.0.27 (from -r requirements.txt (line 12))\n",
            "  Downloading funasr-1.0.27-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting cn2an (from -r requirements.txt (line 13))\n",
            "  Downloading cn2an-0.5.22-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pypinyin (from -r requirements.txt (line 14))\n",
            "  Downloading pypinyin-0.53.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pyopenjtalk>=0.3.4 (from -r requirements.txt (line 15))\n",
            "  Downloading pyopenjtalk-0.3.4.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting g2p_en (from -r requirements.txt (line 16))\n",
            "  Downloading g2p_en-2.1.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting torchaudio (from -r requirements.txt (line 17))\n",
            "  Downloading torchaudio-2.5.1-cp39-cp39-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Collecting modelscope==1.10.0 (from -r requirements.txt (line 18))\n",
            "  Downloading modelscope-1.10.0-py3-none-any.whl.metadata (33 kB)\n",
            "Collecting sentencepiece (from -r requirements.txt (line 19))\n",
            "  Downloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting transformers (from -r requirements.txt (line 20))\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet (from -r requirements.txt (line 21))\n",
            "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting PyYAML (from -r requirements.txt (line 22))\n",
            "  Downloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting psutil (from -r requirements.txt (line 23))\n",
            "  Downloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting jieba_fast (from -r requirements.txt (line 24))\n",
            "  Downloading jieba_fast-0.53.tar.gz (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jieba (from -r requirements.txt (line 25))\n",
            "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting LangSegment>=0.2.0 (from -r requirements.txt (line 26))\n",
            "  Downloading LangSegment-0.3.5-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting Faster_Whisper (from -r requirements.txt (line 27))\n",
            "  Downloading faster_whisper-1.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting wordsegment (from -r requirements.txt (line 28))\n",
            "  Downloading wordsegment-1.3.1-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting rotary_embedding_torch (from -r requirements.txt (line 29))\n",
            "  Downloading rotary_embedding_torch-0.8.6-py3-none-any.whl.metadata (675 bytes)\n",
            "Collecting pyjyutping (from -r requirements.txt (line 30))\n",
            "  Downloading pyjyutping-1.0.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting g2pk2 (from -r requirements.txt (line 31))\n",
            "  Downloading g2pk2-0.0.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting ko_pron (from -r requirements.txt (line 32))\n",
            "  Downloading ko_pron-1.3-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opencc==1.1.1 (from -r requirements.txt (line 34))\n",
            "  Downloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Collecting python_mecab_ko (from -r requirements.txt (line 35))\n",
            "  Downloading python_mecab_ko-1.3.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting fastapi<0.112.2 (from -r requirements.txt (line 36))\n",
            "  Downloading fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting audioread>=2.1.9 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting scikit-learn>=0.19.1 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting joblib>=0.14 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting decorator>=4.0.10 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting soundfile>=0.10.2 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl.metadata (14 kB)\n",
            "Collecting pooch>=1.0 (from librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from librosa==0.9.2->-r requirements.txt (line 4)) (23.1)\n",
            "Collecting llvmlite<0.40,>=0.39.0dev0 (from numba==0.56.4->-r requirements.txt (line 5))\n",
            "  Downloading llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from numba==0.56.4->-r requirements.txt (line 5)) (68.2.2)\n",
            "Collecting jamo (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting kaldiio>=2.17.0 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading kaldiio-2.18.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torch-complex (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading torch_complex-0.4.4-py3-none-any.whl.metadata (3.1 kB)\n",
            "Collecting pytorch-wpe (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl.metadata (242 bytes)\n",
            "Collecting editdistance>=0.5.2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading editdistance-0.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting oss2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading oss2-2.19.1.tar.gz (298 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting umap-learn (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting jaconv (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hydra-core>=1.3.2 (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting tensorboardX (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting openai-whisper (from funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting attrs (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting datasets>=2.14.5 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting einops (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting filelock>=3.3.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gast>=0.2.2 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting pandas (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=6.2.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pillow-11.0.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting pyarrow!=9.0.0,>=6.0.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pyarrow-18.1.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting python-dateutil>=2.1 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: requests>=2.25 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (2.31.0)\n",
            "Collecting simplejson>=3.3.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading simplejson-3.19.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting sortedcontainers>=1.5.9 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.9/site-packages (from modelscope==1.10.0->-r requirements.txt (line 18)) (1.26.18)\n",
            "Collecting yapf (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading yapf-0.43.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading grpcio-1.68.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting protobuf!=4.24.0,>=3.19.6 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting six>1.9 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting torch>=2.1.0 (from pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading torch-2.5.1-cp39-cp39-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting fsspec>=2022.5.0 (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting typing-extensions>=4.4.0 (from pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting altair<6.0,>=4.2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ffmpy (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==0.14.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading gradio_client-0.14.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading httpx-0.28.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting huggingface-hub>=0.19.3 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting importlib-resources<7.0,>=1.3 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jinja2<4.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting markupsafe~=2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting matplotlib~=3.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading matplotlib-3.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting orjson~=3.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading orjson-3.10.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=6.2.0 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydantic>=2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pydantic-2.10.2-py3-none-any.whl.metadata (170 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.8/170.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading python_multipart-0.0.18-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting typer<1.0,>=0.9 (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading typer-0.14.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading uvicorn-0.32.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.14.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting future (from ffmpeg-python->-r requirements.txt (line 8))\n",
            "  Downloading future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting flatbuffers (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting sympy (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting proces>=0.1.3 (from cn2an->-r requirements.txt (line 13))\n",
            "  Downloading proces-0.1.7-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting nltk>=3.2.4 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting inflect>=0.3.1 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading inflect-7.4.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting distance>=0.1.3 (from g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.1.0 (from torch>=2.1.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading triton-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting sympy (from onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting regex!=2019.12.17 (from transformers->-r requirements.txt (line 20))\n",
            "  Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.21,>=0.20 (from transformers->-r requirements.txt (line 20))\n",
            "  Downloading tokenizers-0.20.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting safetensors>=0.4.1 (from transformers->-r requirements.txt (line 20))\n",
            "  Downloading safetensors-0.4.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting py3langid>=0.2.2 (from LangSegment>=0.2.0->-r requirements.txt (line 26))\n",
            "  Downloading py3langid-0.3.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting ctranslate2<5,>=4.0 (from Faster_Whisper->-r requirements.txt (line 27))\n",
            "  Downloading ctranslate2-4.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting onnxruntime<2,>=1.14 (from Faster_Whisper->-r requirements.txt (line 27))\n",
            "  Downloading onnxruntime-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting av>=11 (from Faster_Whisper->-r requirements.txt (line 27))\n",
            "  Downloading av-13.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting python-mecab-ko-dic (from python_mecab_ko->-r requirements.txt (line 35))\n",
            "  Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi<0.112.2->-r requirements.txt (line 36))\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting jsonschema>=3.0 (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting narwhals>=1.14.2 (from altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading narwhals-1.15.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting requests>=2.25 (from modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tqdm (from -r requirements.txt (line 11))\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2022.5.0 (from fsspec[http]>=2022.5.0->pytorch-lightning->-r requirements.txt (line 6))\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting aiohttp (from datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiohttp-3.11.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting anyio (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.9/site-packages (from httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7)) (3.4)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting omegaconf<2.4,>=2.2 (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.3.2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting zipp>=3.1.0 (from importlib-resources<7.0,>=1.3->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting more-itertools>=8.5.0 (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading more_itertools-10.5.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting typeguard>=4.0.1 (from inflect>=0.3.1->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading typeguard-4.4.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting importlib-metadata>=4.4 (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3))\n",
            "  Downloading importlib_metadata-8.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading fonttools-4.55.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib~=3.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click (from nltk>=3.2.4->g2p_en->-r requirements.txt (line 16))\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/site-packages (from pooch>=1.0->librosa==0.9.2->-r requirements.txt (line 4)) (3.10.0)\n",
            "INFO: pip is looking at multiple versions of py3langid to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting py3langid>=0.2.2 (from LangSegment>=0.2.0->-r requirements.txt (line 26))\n",
            "  Downloading py3langid-0.2.2-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.1 (from pydantic>=2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pydantic_core-2.27.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests>=2.25->modelscope==1.10.0->-r requirements.txt (line 18)) (2.0.4)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.19.1->librosa==0.9.2->-r requirements.txt (line 4))\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/site-packages (from soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rich>=10.11.0 (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
            "\u001b[33mWARNING: typer 0.14.0 does not provide the extra 'all'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 10))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting tiktoken (from openai-whisper->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading tiktoken-0.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting crcmod>=1.7 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pycryptodome>=3.4.7 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting aliyun-python-sdk-core>=2.13.12 (from oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pynndescent>=0.5 (from umap-learn->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting tomli>=2.0.1 (from yapf->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading propcache-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets>=2.14.5->modelscope==1.10.0->-r requirements.txt (line 18))\n",
            "  Downloading yarl-1.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12))\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: cryptography>=3.0.0 in /usr/local/lib/python3.9/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr==1.0.27->-r requirements.txt (line 12)) (41.0.7)\n",
            "Collecting sniffio>=1.1 (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting exceptiongroup>=1.0.2 (from anyio->httpx>=0.24.1->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa==0.9.2->-r requirements.txt (line 4)) (2.21)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading rpds_py-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio<=4.24.0,>=4.0->-r requirements.txt (line 7))\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Downloading numpy-1.23.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numba-0.56.4-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funasr-1.0.27-py3-none-any.whl (693 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m693.7/693.7 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading modelscope-1.10.0-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading OpenCC-1.1.1-py2.py3-none-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.4.0-py3-none-any.whl (815 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.2/815.2 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.24.0-py3-none-any.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.14.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.4/312.4 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading onnxruntime_gpu-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (226.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cn2an-0.5.22-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.0/225.0 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypinyin-0.53.0-py2.py3-none-any.whl (834 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m834.7/834.7 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.5.1-cp39-cp39-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.5.1-cp39-cp39-manylinux1_x86_64.whl (906.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.5/906.5 MB\u001b[0m \u001b[31m598.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentencepiece-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (737 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m737.4/737.4 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.3/287.3 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading LangSegment-0.3.5-py3-none-any.whl (28 kB)\n",
            "Downloading faster_whisper-1.1.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wordsegment-1.3.1-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m92.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rotary_embedding_torch-0.8.6-py3-none-any.whl (5.6 kB)\n",
            "Downloading pyjyutping-1.0.0-py3-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.7/143.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading g2pk2-0.0.3-py3-none-any.whl (25 kB)\n",
            "Downloading ko_pron-1.3-py3-none-any.whl (12 kB)\n",
            "Downloading python_mecab_ko-1.3.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.6/578.6 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Downloading av-13.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.3/33.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ctranslate2-4.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading editdistance-0.8.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.6/401.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Downloading grpcio-1.68.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.28.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.6/447.6 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Downloading inflect-7.4.0-py3-none-any.whl (34 kB)\n",
            "Downloading jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.3/133.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaldiio-2.18.0-py3-none-any.whl (28 kB)\n",
            "Downloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading llvmlite-0.39.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading matplotlib-3.9.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.2-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proces-0.1.7-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.0-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading py3langid-0.2.2-py3-none-any.whl (750 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 kB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-18.1.0-cp39-cp39-manylinux_2_28_x86_64.whl (40.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.2-py3-none-any.whl (456 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.18-py3-none-any.whl (24 kB)\n",
            "Downloading regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (780 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.9/780.9 kB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruff-0.8.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safetensors-0.4.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.1/436.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading simplejson-3.19.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.14.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.32.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.3/491.3 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading python_mecab_ko_dic-2.1.1.post2-py3-none-any.whl (34.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
            "Downloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yapf-0.43.0-py3-none-any.whl (256 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.2/256.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.11.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading contourpy-1.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.9/321.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fonttools-4.55.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
            "Downloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading more_itertools-10.5.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.15.0-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.0/232.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodome-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.9/106.9 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
            "Downloading typeguard-4.4.1-py3-none-any.whl (35 kB)\n",
            "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.6/346.6 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.7/129.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.9/193.9 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading frozenlist-1.5.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (242 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.9/242.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Downloading jsonschema_specifications-2024.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.1/124.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading propcache-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading referencing-0.35.1-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.21.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.5/361.5 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading yarl-1.18.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (321 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.2/321.2 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: pyopenjtalk, jieba_fast, jieba, distance, antlr4-python3-runtime, jaconv, openai-whisper, oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for pyopenjtalk (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyopenjtalk: filename=pyopenjtalk-0.3.4-cp39-cp39-linux_x86_64.whl size=1209991 sha256=71129cbeba06a9188c5b044e035f6f9678893183552d74783ca269ed56f23387\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/a4/ce/2fd3035dc55d8dc9f20cffae905f43cc79517aa7560bb856e4\n",
            "  Building wheel for jieba_fast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba_fast: filename=jieba_fast-0.53-cp39-cp39-linux_x86_64.whl size=7628765 sha256=21c8891674f0f241e33b6e8990a52a72209fdd2405281959eae570e47bf042f1\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/04/c8/5c563e7f58588aadfa5af1353a086ef467eb1dadd2fcfac622\n",
            "  Building wheel for jieba (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314458 sha256=8c02f45b20747d65438c99ff06addd1765770bc9457e0eae3c7140a0f5b0f3b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/74/cf/08c94db4b784e2c1ef675a600b7b5b281fd25240dcb954ee7e\n",
            "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=e279926cd43b513597d0437b2f201838ddb580a2207780fcb13c68d108a62537\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/b3/aa/04241cced6d1722b132273b1d6aafba317887ec004f48b853a\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=6d34f0146ac51f0fd66d3ee9b0359f3630dda1334212ca233ae9ebf3b8faddea\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.4.0-py3-none-any.whl size=18227 sha256=e354892f0f04822b96327a669c4e835ff6ddb423093760a645c28bffd5302ee1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/6b/fa/9574efaca6aced07c97ab08d7e40a5cdf8f31ecbe73d55e077\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803320 sha256=53e076435903916841ce66565f3f05321bc4a3b0efdb8b5e5fccab2f9864ad33\n",
            "  Stored in directory: /root/.cache/pip/wheels/94/29/f3/3dd4d7f88df5d701acd3206732dcb6265379c5ece94b472c17\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.19.1-py3-none-any.whl size=123938 sha256=438fabda44a44e167ee873cc06662b6794158c22ffc7029bb51bc3b26da5a0ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/f9/6e/25b9a00f60e4cc7db56fb53f60546568ac3f697e32e3bff38b\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.16.0-py3-none-any.whl size=535317 sha256=295540a82eb3623e3966fea8f86ba2569914206df96d814e3a4c68bdfb2232d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/85/b9/f7c05b089e7fad969001438f8a0175c7233a8635b49d5af57e\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp39-cp39-linux_x86_64.whl size=23178 sha256=f8219a75d8bb8cf7735a6a7ee4cb3d74f1300862560a96de6b4fbe83ec1c494b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/6c/a6/ffdd136310039bf226f2707a9a8e6857be7d70a3fc061f6b36\n",
            "Successfully built pyopenjtalk jieba_fast jieba distance antlr4-python3-runtime jaconv openai-whisper oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: wordsegment, sortedcontainers, sentencepiece, pytz, python-mecab-ko-dic, pyjyutping, pydub, opencc, mpmath, ko_pron, jieba_fast, jieba, jamo, jaconv, flatbuffers, distance, crcmod, antlr4-python3-runtime, addict, zipp, xxhash, websockets, tzdata, typing-extensions, tqdm, tomlkit, tomli, threadpoolctl, tensorboard-data-server, sympy, sniffio, six, simplejson, shellingham, semantic-version, safetensors, ruff, rpds-py, requests, regex, PyYAML, python-multipart, python_mecab_ko, pypinyin, pyparsing, pygments, pycryptodome, pyarrow, psutil, protobuf, propcache, proces, Pillow, orjson, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, narwhals, more-itertools, mdurl, markupsafe, llvmlite, kiwisolver, joblib, jmespath, humanfriendly, h11, grpcio, gast, future, fsspec, frozenlist, fonttools, filelock, ffmpy, exceptiongroup, einops, editdistance, dill, decorator, cycler, click, chardet, av, audioread, attrs, async-timeout, annotated-types, aiohappyeyeballs, aiofiles, absl-py, yapf, werkzeug, uvicorn, triton, torch-complex, tiktoken, tensorboardX, soundfile, scipy, referencing, pytorch-wpe, python-dateutil, pyopenjtalk, pydantic-core, py3langid, pooch, omegaconf, nvidia-cusparse-cu12, nvidia-cudnn-cu12, numba, nltk, multiprocess, multidict, markdown-it-py, lightning-utilities, kaldiio, jinja2, importlib-resources, importlib-metadata, huggingface-hub, httpcore, ffmpeg-python, ctranslate2, contourpy, coloredlogs, cn2an, anyio, aiosignal, yarl, typeguard, tokenizers, starlette, scikit-learn, rich, resampy, pydantic, pandas, onnxruntime-gpu, onnxruntime, nvidia-cusolver-cu12, matplotlib, markdown, LangSegment, jsonschema-specifications, hydra-core, httpx, g2pk2, aliyun-python-sdk-core, typer, transformers, torch, tensorboard, pynndescent, librosa, jsonschema, inflect, gradio-client, Faster_Whisper, fastapi, aliyun-python-sdk-kms, aiohttp, umap-learn, torchmetrics, torchaudio, rotary_embedding_torch, oss2, openai-whisper, g2p_en, altair, pytorch-lightning, gradio, funasr, datasets, modelscope\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "Successfully installed Faster_Whisper-1.1.0 LangSegment-0.3.5 Pillow-10.4.0 PyYAML-6.0.2 absl-py-2.1.0 addict-2.4.0 aiofiles-23.2.1 aiohappyeyeballs-2.4.4 aiohttp-3.11.8 aiosignal-1.3.1 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 altair-5.5.0 annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 anyio-4.6.2.post1 async-timeout-5.0.1 attrs-24.2.0 audioread-3.0.1 av-13.1.0 chardet-5.2.0 click-8.1.7 cn2an-0.5.22 coloredlogs-15.0.1 contourpy-1.3.0 crcmod-1.7 ctranslate2-4.5.0 cycler-0.12.1 datasets-3.1.0 decorator-5.1.1 dill-0.3.8 distance-0.1.3 editdistance-0.8.1 einops-0.8.0 exceptiongroup-1.2.2 fastapi-0.112.1 ffmpeg-python-0.2.0 ffmpy-0.4.0 filelock-3.16.1 flatbuffers-24.3.25 fonttools-4.55.0 frozenlist-1.5.0 fsspec-2024.9.0 funasr-1.0.27 future-1.0.0 g2p_en-2.1.0 g2pk2-0.0.3 gast-0.6.0 gradio-4.24.0 gradio-client-0.14.0 grpcio-1.68.0 h11-0.14.0 httpcore-1.0.7 httpx-0.28.0 huggingface-hub-0.26.3 humanfriendly-10.0 hydra-core-1.3.2 importlib-metadata-8.5.0 importlib-resources-6.4.5 inflect-7.4.0 jaconv-0.4.0 jamo-0.4.1 jieba-0.42.1 jieba_fast-0.53 jinja2-3.1.4 jmespath-0.10.0 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2024.10.1 kaldiio-2.18.0 kiwisolver-1.4.7 ko_pron-1.3 librosa-0.9.2 lightning-utilities-0.11.9 llvmlite-0.39.1 markdown-3.7 markdown-it-py-3.0.0 markupsafe-2.1.5 matplotlib-3.9.3 mdurl-0.1.2 modelscope-1.10.0 more-itertools-10.5.0 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 narwhals-1.15.0 networkx-3.2.1 nltk-3.9.1 numba-0.56.4 numpy-1.23.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 omegaconf-2.3.0 onnxruntime-1.19.2 onnxruntime-gpu-1.19.2 openai-whisper-20240930 opencc-1.1.1 orjson-3.10.12 oss2-2.19.1 pandas-2.2.3 pooch-1.8.2 proces-0.1.7 propcache-0.2.0 protobuf-5.29.0 psutil-6.1.0 py3langid-0.2.2 pyarrow-18.1.0 pycryptodome-3.21.0 pydantic-2.10.2 pydantic-core-2.27.1 pydub-0.25.1 pygments-2.18.0 pyjyutping-1.0.0 pynndescent-0.5.13 pyopenjtalk-0.3.4 pyparsing-3.2.0 pypinyin-0.53.0 python-dateutil-2.9.0.post0 python-mecab-ko-dic-2.1.1.post2 python-multipart-0.0.18 python_mecab_ko-1.3.7 pytorch-lightning-2.4.0 pytorch-wpe-0.0.1 pytz-2024.2 referencing-0.35.1 regex-2024.11.6 requests-2.32.3 resampy-0.4.3 rich-13.9.4 rotary_embedding_torch-0.8.6 rpds-py-0.21.0 ruff-0.8.1 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.13.1 semantic-version-2.10.0 sentencepiece-0.2.0 shellingham-1.5.4 simplejson-3.19.3 six-1.16.0 sniffio-1.3.1 sortedcontainers-2.4.0 soundfile-0.12.1 starlette-0.38.6 sympy-1.13.1 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.2.2 threadpoolctl-3.5.0 tiktoken-0.8.0 tokenizers-0.20.3 tomli-2.2.1 tomlkit-0.12.0 torch-2.5.1 torch-complex-0.4.4 torchaudio-2.5.1 torchmetrics-1.6.0 tqdm-4.67.1 transformers-4.46.3 triton-3.1.0 typeguard-4.4.1 typer-0.14.0 typing-extensions-4.12.2 tzdata-2024.2 umap-learn-0.5.7 uvicorn-0.32.1 websockets-11.0.3 werkzeug-3.1.3 wordsegment-1.3.1 xxhash-3.5.0 yapf-0.43.0 yarl-1.18.0 zipp-3.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download pretrained models 下载预训练模型\n",
        "!mkdir -p /content/GPT-SoVITS/GPT_SoVITS/pretrained_models\n",
        "!mkdir -p /content/GPT-SoVITS/tools/damo_asr/models\n",
        "!mkdir -p /content/GPT-SoVITS/tools/uvr5\n",
        "%cd /content/GPT-SoVITS/GPT_SoVITS/pretrained_models\n",
        "!git clone https://huggingface.co/lj1995/GPT-SoVITS\n",
        "%cd /content/GPT-SoVITS/tools/damo_asr/models\n",
        "!git clone https://www.modelscope.cn/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch.git\n",
        "!git clone https://www.modelscope.cn/damo/speech_fsmn_vad_zh-cn-16k-common-pytorch.git\n",
        "!git clone https://www.modelscope.cn/damo/punc_ct-transformer_zh-cn-common-vocab272727-pytorch.git\n",
        "# @title UVR5 pretrains 安装uvr5模型\n",
        "%cd /content/GPT-SoVITS/tools/uvr5\n",
        "%rm -r uvr5_weights\n",
        "!git clone https://huggingface.co/Delik/uvr5_weights\n",
        "!git config core.sparseCheckout true\n",
        "!mv /content/GPT-SoVITS/GPT_SoVITS/pretrained_models/GPT-SoVITS/* /content/GPT-SoVITS/GPT_SoVITS/pretrained_models/"
      ],
      "metadata": {
        "id": "0NgxXg5sjv7z",
        "outputId": "5c9cb33e-921e-45f8-a659-60bb0b6de52e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GPT-SoVITS/GPT_SoVITS/pretrained_models\n",
            "Cloning into 'GPT-SoVITS'...\n",
            "remote: Enumerating objects: 29, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 29 (delta 3), reused 0 (delta 0), pack-reused 4 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (29/29), 104.78 KiB | 6.16 MiB/s, done.\n",
            "Filtering content: 100% (8/8), 1.44 GiB | 46.77 MiB/s, done.\n",
            "/content/GPT-SoVITS/tools/damo_asr/models\n",
            "Cloning into 'speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch'...\n",
            "remote: Enumerating objects: 466, done.\u001b[K\n",
            "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 466 (delta 38), reused 57 (delta 30), pack-reused 398\u001b[K\n",
            "Receiving objects: 100% (466/466), 1.12 GiB | 12.90 MiB/s, done.\n",
            "Resolving deltas: 100% (268/268), done.\n",
            "Cloning into 'speech_fsmn_vad_zh-cn-16k-common-pytorch'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 184 (delta 18), reused 23 (delta 10), pack-reused 145\u001b[K\n",
            "Receiving objects: 100% (184/184), 4.66 MiB | 19.63 MiB/s, done.\n",
            "Resolving deltas: 100% (91/91), done.\n",
            "Cloning into 'punc_ct-transformer_zh-cn-common-vocab272727-pytorch'...\n",
            "remote: Enumerating objects: 170, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 170 (delta 25), reused 30 (delta 14), pack-reused 120\u001b[K\n",
            "Receiving objects: 100% (170/170), 257.56 MiB | 34.43 MiB/s, done.\n",
            "Resolving deltas: 100% (86/86), done.\n",
            "/content/GPT-SoVITS/tools/uvr5\n",
            "Cloning into 'uvr5_weights'...\n",
            "remote: Enumerating objects: 15, done.\u001b[K\n",
            "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 15 (delta 1), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (15/15), 3.25 KiB | 833.00 KiB/s, done.\n",
            "Filtering content: 100% (9/9), 594.44 MiB | 47.38 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title launch WebUI 启动WebUI\n",
        "!/usr/local/bin/pip install ipykernel\n",
        "!sed -i '10s/False/True/' /content/GPT-SoVITS/config.py\n",
        "%cd /content/GPT-SoVITS/\n",
        "!/usr/local/bin/python  webui.py"
      ],
      "metadata": {
        "id": "4oRGUzkrk8C7",
        "outputId": "bb2dff5e-d053-4b0c-edf1-2510a9b6e01c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipykernel\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting comm>=0.1.1 (from ipykernel)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting debugpy>=1.6.5 (from ipykernel)\n",
            "  Downloading debugpy-1.8.9-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting ipython>=7.23.1 (from ipykernel)\n",
            "  Downloading ipython-8.18.1-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting jupyter-client>=6.1.12 (from ipykernel)\n",
            "  Downloading jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n",
            "  Downloading jupyter_core-5.7.2-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting matplotlib-inline>=0.1 (from ipykernel)\n",
            "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting nest-asyncio (from ipykernel)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from ipykernel) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/site-packages (from ipykernel) (6.1.0)\n",
            "Collecting pyzmq>=24 (from ipykernel)\n",
            "  Downloading pyzmq-26.2.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting tornado>=6.1 (from ipykernel)\n",
            "  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting traitlets>=5.4.0 (from ipykernel)\n",
            "  Downloading traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (5.1.1)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting prompt-toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (2.18.0)\n",
            "Collecting stack-data (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/site-packages (from ipython>=7.23.1->ipykernel) (1.2.2)\n",
            "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (8.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.9/site-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (3.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.9/site-packages (from importlib-metadata>=4.8.3->jupyter-client>=6.1.12->ipykernel) (3.21.0)\n",
            "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel)\n",
            "  Downloading parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting wcwidth (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel)\n",
            "  Downloading wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel) (1.16.0)\n",
            "Collecting executing>=1.2.0 (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting pure-eval (from stack-data->ipython>=7.23.1->ipykernel)\n",
            "  Downloading pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading debugpy-1.8.9-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipython-8.18.1-py3-none-any.whl (808 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m808.2/808.2 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.1/106.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
            "Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
            "Downloading pyzmq-26.2.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (862 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.1/862.1 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Downloading asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
            "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
            "Downloading parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
            "Downloading wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
            "Installing collected packages: wcwidth, pure-eval, ptyprocess, traitlets, tornado, pyzmq, prompt-toolkit, pexpect, parso, nest-asyncio, executing, debugpy, asttokens, stack-data, matplotlib-inline, jupyter-core, jedi, comm, jupyter-client, ipython, ipykernel\n",
            "Successfully installed asttokens-3.0.0 comm-0.2.2 debugpy-1.8.9 executing-2.1.0 ipykernel-6.29.5 ipython-8.18.1 jedi-0.19.2 jupyter-client-8.6.3 jupyter-core-5.7.2 matplotlib-inline-0.1.7 nest-asyncio-1.6.0 parso-0.8.4 pexpect-4.9.0 prompt-toolkit-3.0.48 ptyprocess-0.7.0 pure-eval-0.2.3 pyzmq-26.2.0 stack-data-0.6.3 tornado-6.4.2 traitlets-5.14.3 wcwidth-0.2.13\n",
            "/content/GPT-SoVITS\n",
            "Downloading g2pw model...\n",
            "Extracting g2pw model...\n",
            "Running on local URL:  http://0.0.0.0:9874\n",
            "Running on public URL: https://7c262db2e2c53b61ab.gradio.live\n",
            "\"/usr/local/bin/python\" tools/uvr5/webui.py \"cuda\" True 9873 True\n",
            "Running on local URL:  http://0.0.0.0:9873\n",
            "Running on public URL: https://c15aece0397169c1ca.gradio.live\n",
            "clean_empty_cache\n",
            "ffmpeg version 7.0.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
            "  built with gcc 12.3.0 (conda-forge gcc 12.3.0-7)\n",
            "  configuration: --prefix=/usr/local --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/pkg-config\n",
            "  libavutil      59.  8.100 / 59.  8.100\n",
            "  libavcodec     61.  3.100 / 61.  3.100\n",
            "  libavformat    61.  1.100 / 61.  1.100\n",
            "  libavdevice    61.  1.100 / 61.  1.100\n",
            "  libavfilter    10.  1.100 / 10.  1.100\n",
            "  libswscale      8.  1.100 /  8.  1.100\n",
            "  libswresample   5.  1.100 /  5.  1.100\n",
            "  libpostproc    58.  1.100 / 58.  1.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/龙光城南一期高层.m4a':\n",
            "  Metadata:\n",
            "    major_brand     : M4A \n",
            "    minor_version   : 0\n",
            "    compatible_brands: M4A isommp42\n",
            "    creation_time   : 2024-12-01T00:00:46.000000Z\n",
            "    title           : 龙光城南一期高层\n",
            "    voice-memo-uuid : 30E328AB-978A-4A32-9454-6065F915538A\n",
            "    encoder         : com.apple.VoiceMemos (iPhone Version 17.5.1 (Build 21F90))\n",
            "  Duration: 00:01:14.73, start: 0.000000, bitrate: 68 kb/s\n",
            "  Stream #0:0[0x1](und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 64 kb/s (default)\n",
            "      Metadata:\n",
            "        creation_time   : 2024-12-01T00:00:46.000000Z\n",
            "        handler_name    : Core Media Audio\n",
            "        vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/GPT-SoVITS/TEMP/龙光城南一期高层.m4a.reformatted.wav':\n",
            "  Metadata:\n",
            "    major_brand     : M4A \n",
            "    minor_version   : 0\n",
            "    compatible_brands: M4A isommp42\n",
            "    voice-memo-uuid : 30E328AB-978A-4A32-9454-6065F915538A\n",
            "    INAM            : 龙光城南一期高层\n",
            "    ISFT            : Lavf61.1.100\n",
            "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
            "      Metadata:\n",
            "        creation_time   : 2024-12-01T00:00:46.000000Z\n",
            "        handler_name    : Core Media Audio\n",
            "        vendor_id       : [0][0][0][0]\n",
            "        encoder         : Lavc61.3.100 pcm_s16le\n",
            "\u001b[1;35m[out#0/wav @ 0x56e0ed0e37c0] \u001b[0mvideo:0KiB audio:12874KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000850%\n",
            "size=   12874KiB time=00:01:14.73 bitrate=1411.2kbits/s speed= 483x    \n",
            "100% 27/27 [00:03<00:00,  8.15it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/uvr5/webui.py\", line 77, in uvr\n",
            "    info = ffmpeg.probe(inp_path, cmd=\"ffprobe\")\n",
            "  File \"/usr/local/lib/python3.9/site-packages/ffmpeg/_probe.py\", line 23, in probe\n",
            "    raise Error('ffprobe', out, err)\n",
            "ffmpeg._run.Error: ffprobe error (see stderr output for detail)\n",
            "ffmpeg version 7.0.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
            "  built with gcc 12.3.0 (conda-forge gcc 12.3.0-7)\n",
            "  configuration: --prefix=/usr/local --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/pkg-config\n",
            "  libavutil      59.  8.100 / 59.  8.100\n",
            "  libavcodec     61.  3.100 / 61.  3.100\n",
            "  libavformat    61.  1.100 / 61.  1.100\n",
            "  libavdevice    61.  1.100 / 61.  1.100\n",
            "  libavfilter    10.  1.100 / 10.  1.100\n",
            "  libswscale      8.  1.100 /  8.  1.100\n",
            "  libswresample   5.  1.100 /  5.  1.100\n",
            "  libpostproc    58.  1.100 / 58.  1.100\n",
            "\u001b[0;35m[in#0 @ 0x5caedfbc6800] \u001b[0m\u001b[1;31mError opening input: Invalid data found when processing input\n",
            "\u001b[0m\u001b[1;31mError opening input file /content/condacolab_install.log.\n",
            "\u001b[0m\u001b[4;31mError opening input files: Invalid data found when processing input\n",
            "\u001b[0mclean_empty_cache\n",
            "ffmpeg version 7.0.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
            "  built with gcc 12.3.0 (conda-forge gcc 12.3.0-7)\n",
            "  configuration: --prefix=/usr/local --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-libass --enable-pthreads --enable-vaapi --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libopus --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1716729489913/_build_env/bin/pkg-config\n",
            "  libavutil      59.  8.100 / 59.  8.100\n",
            "  libavcodec     61.  3.100 / 61.  3.100\n",
            "  libavformat    61.  1.100 / 61.  1.100\n",
            "  libavdevice    61.  1.100 / 61.  1.100\n",
            "  libavfilter    10.  1.100 / 10.  1.100\n",
            "  libswscale      8.  1.100 /  8.  1.100\n",
            "  libswresample   5.  1.100 /  5.  1.100\n",
            "  libpostproc    58.  1.100 / 58.  1.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '/content/input/龙光城南一期高层.m4a':\n",
            "  Metadata:\n",
            "    major_brand     : M4A \n",
            "    minor_version   : 0\n",
            "    compatible_brands: M4A isommp42\n",
            "    creation_time   : 2024-12-01T00:00:46.000000Z\n",
            "    title           : 龙光城南一期高层\n",
            "    voice-memo-uuid : 30E328AB-978A-4A32-9454-6065F915538A\n",
            "    encoder         : com.apple.VoiceMemos (iPhone Version 17.5.1 (Build 21F90))\n",
            "  Duration: 00:01:14.73, start: 0.000000, bitrate: 68 kb/s\n",
            "  Stream #0:0[0x1](und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 64 kb/s (default)\n",
            "      Metadata:\n",
            "        creation_time   : 2024-12-01T00:00:46.000000Z\n",
            "        handler_name    : Core Media Audio\n",
            "        vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/GPT-SoVITS/TEMP/龙光城南一期高层.m4a.reformatted.wav':\n",
            "  Metadata:\n",
            "    major_brand     : M4A \n",
            "    minor_version   : 0\n",
            "    compatible_brands: M4A isommp42\n",
            "    voice-memo-uuid : 30E328AB-978A-4A32-9454-6065F915538A\n",
            "    INAM            : 龙光城南一期高层\n",
            "    ISFT            : Lavf61.1.100\n",
            "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, stereo, s16, 1411 kb/s (default)\n",
            "      Metadata:\n",
            "        creation_time   : 2024-12-01T00:00:46.000000Z\n",
            "        handler_name    : Core Media Audio\n",
            "        vendor_id       : [0][0][0][0]\n",
            "        encoder         : Lavc61.3.100 pcm_s16le\n",
            "\u001b[1;35m[out#0/wav @ 0x5a997f389800] \u001b[0mvideo:0KiB audio:12874KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.000850%\n",
            "size=   12874KiB time=00:01:14.73 bitrate=1411.2kbits/s speed= 408x    \n",
            "100% 27/27 [00:01<00:00, 15.75it/s]\n",
            "clean_empty_cache\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 4000 300 10 500 0.9 0.25 3 4\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 20, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "/content/GPT-SoVITS/output/uvr5_opt/.ipynb_checkpoints ->fail-> Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 20, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/slice_audio.py\", line 31, in slice\n",
            "    audio = load_audio(inp_path, 32000)\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 26, in load_audio\n",
            "    raise RuntimeError(i18n(\"音频加载失败\"))\n",
            "RuntimeError: Failed to Load Audio\n",
            "\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 3000 300 10 500 0.9 0.25 0 4\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 3000 300 10 500 0.9 0.25 1 4\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 3000 300 10 500 0.9 0.25 2 4\n",
            "\"/usr/local/bin/python\" tools/slice_audio.py \"/content/GPT-SoVITS/output/uvr5_opt\" \"output/slicer_opt\" -34 3000 300 10 500 0.9 0.25 3 4\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 20, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "/content/GPT-SoVITS/output/uvr5_opt/.ipynb_checkpoints ->fail-> Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 20, in load_audio\n",
            "    ffmpeg.input(file, threads=0)\n",
            "  File \"/usr/local/lib/python3.9/site-packages/ffmpeg/_run.py\", line 325, in run\n",
            "    raise Error('ffmpeg', out, err)\n",
            "ffmpeg._run.Error: ffmpeg error (see stderr output for detail)\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/tools/slice_audio.py\", line 31, in slice\n",
            "    audio = load_audio(inp_path, 32000)\n",
            "  File \"/content/GPT-SoVITS/tools/my_utils.py\", line 26, in load_audio\n",
            "    raise RuntimeError(i18n(\"音频加载失败\"))\n",
            "RuntimeError: Failed to Load Audio\n",
            "\n",
            "执行完毕，请检查输出文件\n",
            "执行完毕，请检查输出文件\n",
            "\"/usr/local/bin/python\" tools/asr/funasr_asr.py -i \"/content/GPT-SoVITS/output/slicer_opt\" -o \"output/asr_opt\" -s large -l zh -p float32\n",
            "2024-12-01 00:39:03,584 - modelscope - INFO - PyTorch version 2.5.1 Found.\n",
            "2024-12-01 00:39:03,585 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
            "2024-12-01 00:39:03,585 - modelscope - INFO - No valid ast index found from /root/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
            "2024-12-01 00:39:03,646 - modelscope - INFO - Loading done! Current index file version is 1.10.0, with md5 2b31427fc14359d02d1a89c19bc602c6 and a total number of 946 components indexed\n",
            "2024-12-01 00:39:05,094 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 10.9k/10.9k [00:00<00:00, 616kB/s]\n",
            "Downloading: 100% 173k/173k [00:00<00:00, 3.21MB/s]\n",
            "Downloading: 100% 2.45k/2.45k [00:00<00:00, 956kB/s]\n",
            "Downloading: 100% 472/472 [00:00<00:00, 182kB/s]\n",
            "Downloading: 100% 840M/840M [00:07<00:00, 119MB/s]\n",
            "Downloading: 100% 19.1k/19.1k [00:00<00:00, 1.14MB/s]\n",
            "Downloading: 100% 7.90M/7.90M [00:00<00:00, 39.5MB/s]\n",
            "Downloading: 100% 48.7k/48.7k [00:00<00:00, 1.26MB/s]\n",
            "Downloading: 100% 91.5k/91.5k [00:00<00:00, 2.64MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt\n",
            "/usr/local/lib/python3.9/site-packages/funasr/train_utils/load_pretrained_model.py:68: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  src_state = torch.load(path, map_location=map_location)\n",
            "2024-12-01 00:39:33,677 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 7.85k/7.85k [00:00<00:00, 2.50MB/s]\n",
            "Downloading: 100% 1.19k/1.19k [00:00<00:00, 438kB/s]\n",
            "Downloading: 100% 365/365 [00:00<00:00, 130kB/s]\n",
            "Downloading: 100% 1.64M/1.64M [00:00<00:00, 11.8MB/s]\n",
            "Downloading: 100% 8.45k/8.45k [00:00<00:00, 3.00MB/s]\n",
            "Downloading: 100% 27.3k/27.3k [00:00<00:00, 1.44MB/s]\n",
            "Downloading: 100% 2.16M/2.16M [00:00<00:00, 14.4MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt\n",
            "2024-12-01 00:39:45,127 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
            "Downloading: 100% 6.00k/6.00k [00:00<00:00, 1.93MB/s]\n",
            "Downloading: 100% 810/810 [00:00<00:00, 297kB/s]\n",
            "Downloading: 100% 373/373 [00:00<00:00, 136kB/s]\n",
            "Downloading: 100% 278M/278M [00:03<00:00, 90.8MB/s]\n",
            "Downloading: 100% 863/863 [00:00<00:00, 316kB/s]\n",
            "Downloading: 100% 11.2k/11.2k [00:00<00:00, 4.14MB/s]\n",
            "Downloading: 100% 151k/151k [00:00<00:00, 2.59MB/s]\n",
            "Downloading: 100% 4.01M/4.01M [00:00<00:00, 24.0MB/s]\n",
            "ckpt: /root/.cache/modelscope/hub/iic/punc_ct-transformer_zh-cn-common-vocab272727-pytorch/model.pt\n",
            "FunASR 模型加载完成: ZH\n",
            "  0% 0/17 [00:00<?, ?it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000014720_0000176640.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  1.52it/s]\u001b[A\n",
            "{'load_data': '0.299', 'extract_feat': '0.132', 'forward': '0.658', 'batch_size': '1', 'rtf': '0.131'}, : 100% 1/1 [00:00<00:00,  1.52it/s]\u001b[A\n",
            "rtf_avg: 0.131: 100% 1/1 [00:00<00:00,  1.52it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A/usr/local/lib/python3.9/site-packages/funasr/models/paraformer/model.py:249: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "/usr/local/lib/python3.9/site-packages/funasr/models/paraformer/cif_predictor.py:212: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast(False):\n",
            "\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.20s/it]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '1.198', 'batch_size': '1', 'rtf': '0.247'}, : 100% 1/1 [00:01<00:00,  1.20s/it]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.247: 100% 1/1 [00:01<00:00,  1.20s/it]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.069', 'batch_size': '1', 'rtf': '-0.069'}, : 100% 1/1 [00:00<00:00, 14.57it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.069: 100% 1/1 [00:00<00:00, 14.52it/s]\n",
            "\n",
            "100% 1/1 [00:01<00:00,  1.29s/it]\u001b[A\n",
            "rtf_avg: 0.252, time_speech:  5.060, time_escape: 1.273: 100% 1/1 [00:01<00:00,  1.29s/it]\n",
            "  6% 1/17 [00:01<00:31,  1.95s/it]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000178560_0000285120.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.013', 'extract_feat': '0.008', 'forward': '0.050', 'batch_size': '1', 'rtf': '0.015'}, : 100% 1/1 [00:00<00:00, 19.87it/s]\u001b[A\n",
            "rtf_avg: 0.015: 100% 1/1 [00:00<00:00, 19.69it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.006', 'forward': '0.096', 'batch_size': '1', 'rtf': '0.031'}, : 100% 1/1 [00:00<00:00, 10.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.031: 100% 1/1 [00:00<00:00, 10.35it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 156.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 149.44it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.28it/s]\u001b[A\n",
            "rtf_avg: 0.033, time_speech:  3.330, time_escape: 0.108: 100% 1/1 [00:00<00:00,  8.26it/s]\n",
            " 12% 2/17 [00:02<00:13,  1.11it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000330880_0000543680.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.015', 'extract_feat': '0.015', 'forward': '0.086', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00, 11.62it/s]\u001b[A\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 11.53it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.009', 'forward': '0.136', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00,  7.38it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00,  7.33it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 73.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 71.58it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.89it/s]\u001b[A\n",
            "rtf_avg: 0.023, time_speech:  6.650, time_escape: 0.155: 100% 1/1 [00:00<00:00,  5.88it/s]\n",
            " 18% 3/17 [00:02<00:08,  1.64it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000614720_0000729280.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.013', 'extract_feat': '0.008', 'forward': '0.052', 'batch_size': '1', 'rtf': '0.015'}, : 100% 1/1 [00:00<00:00, 19.07it/s]\u001b[A\n",
            "rtf_avg: 0.015: 100% 1/1 [00:00<00:00, 18.89it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.006', 'forward': '0.111', 'batch_size': '1', 'rtf': '0.031'}, : 100% 1/1 [00:00<00:00,  8.99it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.031: 100% 1/1 [00:00<00:00,  8.92it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.007', 'batch_size': '1', 'rtf': '-0.007'}, : 100% 1/1 [00:00<00:00, 142.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.007: 100% 1/1 [00:00<00:00, 136.60it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.12it/s]\u001b[A\n",
            "rtf_avg: 0.035, time_speech:  3.580, time_escape: 0.125: 100% 1/1 [00:00<00:00,  7.11it/s]\n",
            " 24% 4/17 [00:02<00:05,  2.25it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000751040_0000892800.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.014', 'extract_feat': '0.009', 'forward': '0.061', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00, 16.29it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 16.21it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.106', 'batch_size': '1', 'rtf': '0.024'}, : 100% 1/1 [00:00<00:00,  9.47it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.024: 100% 1/1 [00:00<00:00,  9.40it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.007', 'batch_size': '1', 'rtf': '-0.007'}, : 100% 1/1 [00:00<00:00, 143.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.007: 100% 1/1 [00:00<00:00, 138.13it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.58it/s]\u001b[A\n",
            "rtf_avg: 0.027, time_speech:  4.430, time_escape: 0.119: 100% 1/1 [00:00<00:00,  7.56it/s]\n",
            " 29% 5/17 [00:02<00:04,  2.82it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000912000_0001023680.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.013', 'extract_feat': '0.008', 'forward': '0.057', 'batch_size': '1', 'rtf': '0.016'}, : 100% 1/1 [00:00<00:00, 17.54it/s]\u001b[A\n",
            "rtf_avg: 0.016: 100% 1/1 [00:00<00:00, 17.38it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.107', 'batch_size': '1', 'rtf': '0.031'}, : 100% 1/1 [00:00<00:00,  9.30it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.031: 100% 1/1 [00:00<00:00,  9.22it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.007', 'batch_size': '1', 'rtf': '-0.007'}, : 100% 1/1 [00:00<00:00, 133.41it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.007: 100% 1/1 [00:00<00:00, 126.04it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.37it/s]\u001b[A\n",
            "rtf_avg: 0.035, time_speech:  3.490, time_escape: 0.122: 100% 1/1 [00:00<00:00,  7.36it/s]\n",
            " 35% 6/17 [00:02<00:03,  3.33it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001073280_0001148160.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.015', 'extract_feat': '0.007', 'forward': '0.047', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00, 21.16it/s]\u001b[A\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00, 20.97it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.005', 'forward': '0.095', 'batch_size': '1', 'rtf': '0.044'}, : 100% 1/1 [00:00<00:00, 10.55it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.044: 100% 1/1 [00:00<00:00, 10.49it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 169.26it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 162.78it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.41it/s]\u001b[A\n",
            "rtf_avg: 0.046, time_speech:  2.340, time_escape: 0.107: 100% 1/1 [00:00<00:00,  8.40it/s]\n",
            " 41% 7/17 [00:03<00:02,  3.89it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001073280_0001313280.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.016', 'extract_feat': '0.017', 'forward': '0.094', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00, 10.67it/s]\u001b[A\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 10.60it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50% 1/2 [00:00<00:00,  7.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.013', 'forward': '0.137', 'batch_size': '2', 'rtf': '0.019'}, :  50% 1/2 [00:00<00:00,  7.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.019:  50% 1/2 [00:00<00:00,  7.29it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 74.45it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 72.98it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  5.84it/s]\u001b[A\n",
            "rtf_avg: 0.021, time_speech:  7.500, time_escape: 0.156: 100% 1/1 [00:00<00:00,  5.84it/s]\n",
            " 47% 8/17 [00:03<00:02,  3.84it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001164800_0001313280.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.014', 'extract_feat': '0.009', 'forward': '0.064', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00, 15.67it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 15.55it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.007', 'forward': '0.118', 'batch_size': '1', 'rtf': '0.026'}, : 100% 1/1 [00:00<00:00,  8.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.026: 100% 1/1 [00:00<00:00,  8.42it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 78.92it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 77.31it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.65it/s]\u001b[A\n",
            "rtf_avg: 0.029, time_speech:  4.640, time_escape: 0.137: 100% 1/1 [00:00<00:00,  6.64it/s]\n",
            " 53% 9/17 [00:03<00:01,  4.06it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001348480_0001456960.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.014', 'extract_feat': '0.008', 'forward': '0.058', 'batch_size': '1', 'rtf': '0.017'}, : 100% 1/1 [00:00<00:00, 17.15it/s]\u001b[A\n",
            "rtf_avg: 0.017: 100% 1/1 [00:00<00:00, 17.07it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.005', 'forward': '0.111', 'batch_size': '1', 'rtf': '0.034'}, : 100% 1/1 [00:00<00:00,  8.98it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.034: 100% 1/1 [00:00<00:00,  8.91it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 168.21it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 161.82it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.32it/s]\u001b[A\n",
            "rtf_avg: 0.036, time_speech:  3.390, time_escape: 0.123: 100% 1/1 [00:00<00:00,  7.31it/s]\n",
            " 59% 10/17 [00:03<00:01,  4.33it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001348480_0001536960.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.016', 'extract_feat': '0.011', 'forward': '0.076', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00, 13.06it/s]\u001b[A\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 12.95it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.008', 'forward': '0.115', 'batch_size': '1', 'rtf': '0.020'}, : 100% 1/1 [00:00<00:00,  8.67it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.020: 100% 1/1 [00:00<00:00,  8.60it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.007', 'batch_size': '1', 'rtf': '-0.007'}, : 100% 1/1 [00:00<00:00, 137.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.007: 100% 1/1 [00:00<00:00, 129.55it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.94it/s]\u001b[A\n",
            "rtf_avg: 0.022, time_speech:  5.890, time_escape: 0.129: 100% 1/1 [00:00<00:00,  6.92it/s]\n",
            " 65% 11/17 [00:04<00:01,  4.38it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001456960_0001536960.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.014', 'extract_feat': '0.007', 'forward': '0.043', 'batch_size': '1', 'rtf': '0.017'}, : 100% 1/1 [00:00<00:00, 23.17it/s]\u001b[A\n",
            "rtf_avg: 0.017: 100% 1/1 [00:00<00:00, 22.93it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.005', 'forward': '0.090', 'batch_size': '1', 'rtf': '0.036'}, : 100% 1/1 [00:00<00:00, 11.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.036: 100% 1/1 [00:00<00:00, 11.04it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 165.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 158.25it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.70it/s]\u001b[A\n",
            "rtf_avg: 0.041, time_speech:  2.500, time_escape: 0.102: 100% 1/1 [00:00<00:00,  8.68it/s]\n",
            " 71% 12/17 [00:04<00:01,  4.82it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001691840_0001903360.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.016', 'extract_feat': '0.011', 'forward': '0.089', 'batch_size': '1', 'rtf': '0.013'}, : 100% 1/1 [00:00<00:00, 11.22it/s]\u001b[A\n",
            "rtf_avg: 0.013: 100% 1/1 [00:00<00:00, 11.16it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.010', 'forward': '0.111', 'batch_size': '1', 'rtf': '0.017'}, : 100% 1/1 [00:00<00:00,  9.01it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.017: 100% 1/1 [00:00<00:00,  8.94it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.013', 'batch_size': '1', 'rtf': '-0.013'}, : 100% 1/1 [00:00<00:00, 77.51it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.013: 100% 1/1 [00:00<00:00, 74.95it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.82it/s]\u001b[A\n",
            "rtf_avg: 0.020, time_speech:  6.610, time_escape: 0.130: 100% 1/1 [00:00<00:00,  6.81it/s]\n",
            " 76% 13/17 [00:04<00:00,  4.62it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001904000_0001995520.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.013', 'extract_feat': '0.007', 'forward': '0.046', 'batch_size': '1', 'rtf': '0.016'}, : 100% 1/1 [00:00<00:00, 21.77it/s]\u001b[A\n",
            "rtf_avg: 0.016: 100% 1/1 [00:00<00:00, 21.56it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.005', 'forward': '0.110', 'batch_size': '1', 'rtf': '0.039'}, : 100% 1/1 [00:00<00:00,  9.11it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.039: 100% 1/1 [00:00<00:00,  9.03it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 166.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 159.58it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.41it/s]\u001b[A\n",
            "rtf_avg: 0.043, time_speech:  2.860, time_escape: 0.122: 100% 1/1 [00:00<00:00,  7.40it/s]\n",
            " 82% 14/17 [00:04<00:00,  4.85it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001904000_0002142400.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.015', 'extract_feat': '0.013', 'forward': '0.087', 'batch_size': '1', 'rtf': '0.012'}, : 100% 1/1 [00:00<00:00, 11.42it/s]\u001b[A\n",
            "rtf_avg: 0.012: 100% 1/1 [00:00<00:00, 11.39it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            " 50% 1/2 [00:00<00:00,  9.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.012', 'forward': '0.105', 'batch_size': '2', 'rtf': '0.015'}, :  50% 1/2 [00:00<00:00,  9.49it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.015:  50% 1/2 [00:00<00:00,  9.42it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.012', 'batch_size': '1', 'rtf': '-0.012'}, : 100% 1/1 [00:00<00:00, 80.07it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.012: 100% 1/1 [00:00<00:00, 77.38it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.19it/s]\u001b[A\n",
            "rtf_avg: 0.017, time_speech:  7.450, time_escape: 0.124: 100% 1/1 [00:00<00:00,  7.17it/s]\n",
            " 88% 15/17 [00:04<00:00,  4.70it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0002020800_0002142400.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.016', 'extract_feat': '0.010', 'forward': '0.061', 'batch_size': '1', 'rtf': '0.016'}, : 100% 1/1 [00:00<00:00, 16.37it/s]\u001b[A\n",
            "rtf_avg: 0.016: 100% 1/1 [00:00<00:00, 16.23it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  8.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.008', 'forward': '0.117', 'batch_size': '1', 'rtf': '0.031'}, : 100% 1/1 [00:00<00:00,  8.52it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.031: 100% 1/1 [00:00<00:00,  8.47it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.006', 'batch_size': '1', 'rtf': '-0.006'}, : 100% 1/1 [00:00<00:00, 155.91it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.006: 100% 1/1 [00:00<00:00, 150.33it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  6.92it/s]\u001b[A\n",
            "rtf_avg: 0.035, time_speech:  3.800, time_escape: 0.132: 100% 1/1 [00:00<00:00,  6.91it/s]\n",
            " 94% 16/17 [00:05<00:00,  4.73it/s]\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0002142400_0002343040.wav\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "{'load_data': '0.016', 'extract_feat': '0.011', 'forward': '0.089', 'batch_size': '1', 'rtf': '0.014'}, : 100% 1/1 [00:00<00:00, 11.28it/s]\u001b[A\n",
            "rtf_avg: 0.014: 100% 1/1 [00:00<00:00, 11.21it/s]\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "100% 1/1 [00:00<00:00,  9.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': '0.000', 'extract_feat': '0.008', 'forward': '0.103', 'batch_size': '1', 'rtf': '0.019'}, : 100% 1/1 [00:00<00:00,  9.66it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: 0.019: 100% 1/1 [00:00<00:00,  9.61it/s]\n",
            "\n",
            "\n",
            "  0% 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "{'load_data': 0.0, 'extract_feat': 0.0, 'forward': '0.012', 'batch_size': '1', 'rtf': '-0.012'}, : 100% 1/1 [00:00<00:00, 80.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "rtf_avg: -0.012: 100% 1/1 [00:00<00:00, 78.86it/s]\n",
            "\n",
            "100% 1/1 [00:00<00:00,  7.10it/s]\u001b[A\n",
            "rtf_avg: 0.020, time_speech:  6.270, time_escape: 0.124: 100% 1/1 [00:00<00:00,  7.09it/s]\n",
            "100% 17/17 [00:05<00:00,  3.22it/s]\n",
            "ASR 任务完成->标注文件路径: /content/GPT-SoVITS/output/asr_opt/slicer_opt.list\n",
            "\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/1-get-text.py\n",
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
            "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
            "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
            "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000014720_0000176640.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000178560_0000285120.wav\n",
            "当前使用g2pw进行拼音推理\n",
            "当前使用g2pw进行拼音推理\n",
            "Building prefix dict from the default dictionary ...\n",
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /content/GPT-SoVITS/TEMP/jieba.cache\n",
            "Loading model cost 1.980 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "Dumping model to file cache /content/GPT-SoVITS/TEMP/jieba.cache\n",
            "Loading model cost 2.269 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000330880_0000543680.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000614720_0000729280.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000912000_0001023680.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001073280_0001313280.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000751040_0000892800.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001348480_0001456960.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001073280_0001148160.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001456960_0001536960.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001164800_0001313280.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001904000_0001995520.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0002020800_0002142400.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001348480_0001536960.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001691840_0001903360.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001904000_0002142400.wav\n",
            "vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0002142400_0002343040.wav\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/2-get-hubert-wav32k.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/prepare_datasets/3-get-semantic.py\n",
            "<All keys matched successfully>\n",
            "<All keys matched successfully>\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/s1_train.py --config_file \"/content/GPT-SoVITS/TEMP/tmp_s1.yaml\" \n",
            "Seed set to 1234\n",
            "Using 16bit Automatic Mixed Precision (AMP)\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/models/t2s_lightning_module.py:26: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "<All keys matched successfully>\n",
            "ckpt_path: None\n",
            "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
            "----------------------------------------------------------------------------------------------------\n",
            "distributed_backend=nccl\n",
            "All distributed processes registered. Starting with 1 processes\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "semantic_data_len: 17\n",
            "phoneme_data_len: 17\n",
            "                                            item_name                                     semantic_audio\n",
            "0   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000...  520 105 53 490 641 248 699 647 263 318 875 451...\n",
            "1   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000...  623 106 960 347 152 751 129 751 42 631 355 666...\n",
            "2   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000...  208 760 347 347 949 742 446 742 495 300 408 29...\n",
            "3   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  520 271 105 105 280 280 280 280 280 53 234 98 ...\n",
            "4   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  208 509 1017 530 837 1002 187 145 1020 233 276...\n",
            "5   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  1005 239 214 775 797 663 623 623 75 318 775 98...\n",
            "6   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  721 242 764 962 462 393 765 307 915 270 945 51...\n",
            "7   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  208 213 241 407 1003 600 992 806 77 981 758 54...\n",
            "8   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0002...  214 214 965 16 638 339 601 270 339 817 477 99 ...\n",
            "9   vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000...  774 797 699 237 237 273 273 240 750 103 837 21...\n",
            "10  vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000...  208 365 200 697 901 765 307 661 850 963 559 73...\n",
            "11  vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0000...  208 14 831 583 789 631 666 719 250 325 514 668...\n",
            "12  vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  520 105 280 486 486 486 486 486 486 280 53 405...\n",
            "13  vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  1005 90 214 775 797 663 965 623 17 17 190 663 ...\n",
            "14  vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  214 17 17 242 197 513 484 988 772 229 17 947 1...\n",
            "15  vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0001...  208 311 241 407 137 600 992 806 77 116 758 549...\n",
            "16  vocal_龙光城南一期高层.m4a.reformatted.wav_10.wav_0002...  1005 8 902 763 992 444 985 619 250 444 422 784...\n",
            "dataset.__len__(): 85\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name  | Type                 | Params | Mode \n",
            "-------------------------------------------------------\n",
            "0 | model | Text2SemanticDecoder | 77.6 M | train\n",
            "-------------------------------------------------------\n",
            "77.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "77.6 M    Total params\n",
            "310.426   Total estimated model params size (MB)\n",
            "257       Modules in train mode\n",
            "0         Modules in eval mode\n",
            "/usr/local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "/usr/local/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "/content/GPT-SoVITS/GPT_SoVITS/AR/data/dataset.py:230: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  bert_feature = torch.load(path_bert, map_location=\"cpu\")\n",
            "Epoch 14: 100% 13/13 [00:01<00:00,  8.22it/s, v_num=0, total_loss_step=103.0, lr_step=0.002, top_3_acc_step=0.993, total_loss_epoch=545.0, lr_epoch=0.002, top_3_acc_epoch=0.991]`Trainer.fit` stopped: `max_epochs=15` reached.\n",
            "Epoch 14: 100% 13/13 [00:19<00:00,  1.53s/it, v_num=0, total_loss_step=103.0, lr_step=0.002, top_3_acc_step=0.993, total_loss_epoch=545.0, lr_epoch=0.002, top_3_acc_epoch=0.991]\n",
            "\"/usr/local/bin/python\" GPT_SoVITS/inference_webui.py \"Auto\"\n",
            "<All keys matched successfully>\n",
            "Number of parameter: 77.49M\n",
            "Running on local URL:  http://0.0.0.0:9872\n",
            "Running on public URL: https://0ece7dbedbafd29f8e.gradio.live\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽\n",
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba_fast:Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /content/GPT-SoVITS/TEMP/jieba.cache\n",
            "DEBUG:jieba_fast:Loading model from cache /content/GPT-SoVITS/TEMP/jieba.cache\n",
            "Loading model cost 0.783 seconds.\n",
            "DEBUG:jieba_fast:Loading model cost 0.783 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "DEBUG:jieba_fast:Prefix dict has been built succesfully.\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽.\n",
            "  2% 30/1500 [00:00<00:21, 69.91it/s]T2S Decoding EOS [184 -> 216]\n",
            "  2% 31/1500 [00:00<00:29, 50.34it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "2.185\t0.869\t0.630\t1.544\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  4% 66/1500 [00:00<00:13, 102.85it/s]T2S Decoding EOS [184 -> 252]\n",
            "  4% 67/1500 [00:00<00:14, 100.48it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.190\t0.045\t0.669\t0.376\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  4% 67/1500 [00:00<00:13, 103.11it/s]T2S Decoding EOS [184 -> 255]\n",
            "  5% 70/1500 [00:00<00:14, 98.64it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.212\t0.049\t0.712\t0.637\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  6% 89/1500 [00:00<00:13, 101.52it/s]T2S Decoding EOS [184 -> 278]\n",
            "  6% 93/1500 [00:00<00:13, 101.51it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.198\t0.043\t0.918\t0.315\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  2% 26/1500 [00:00<00:16, 89.71it/s]T2S Decoding EOS [184 -> 218]\n",
            "  2% 33/1500 [00:00<00:17, 81.83it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.185\t0.044\t0.405\t0.322\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  3% 47/1500 [00:00<00:12, 114.86it/s]T2S Decoding EOS [184 -> 232]\n",
            "  3% 47/1500 [00:00<00:13, 110.71it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.213\t0.042\t0.426\t0.306\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  5% 68/1500 [00:00<00:13, 108.94it/s]T2S Decoding EOS [184 -> 254]\n",
            "  5% 69/1500 [00:00<00:13, 106.31it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.200\t0.045\t0.651\t0.321\n",
            "Number of parameter: 77.61M\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  1% 11/1500 [00:00<00:14, 103.04it/s]T2S Decoding EOS [184 -> 196]\n",
            "  1% 11/1500 [00:00<00:15, 94.90it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.186\t0.042\t0.124\t0.334\n",
            "Number of parameter: 77.61M\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  1% 11/1500 [00:00<00:13, 108.38it/s]T2S Decoding EOS [184 -> 201]\n",
            "  1% 16/1500 [00:00<00:14, 99.04it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.188\t0.043\t0.168\t0.352\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  1% 11/1500 [00:00<00:14, 101.93it/s]T2S Decoding EOS [184 -> 199]\n",
            "  1% 14/1500 [00:00<00:15, 97.86it/s] \n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.186\t0.043\t0.145\t0.326\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  1% 14/1500 [00:00<00:22, 66.20it/s]T2S Decoding EOS [184 -> 203]\n",
            "  1% 18/1500 [00:00<00:23, 63.12it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.307\t0.070\t0.288\t0.506\n",
            "Number of parameter: 77.61M\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  5% 69/1500 [00:00<00:12, 110.87it/s]T2S Decoding EOS [184 -> 260]\n",
            "  5% 75/1500 [00:00<00:13, 108.40it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.195\t0.042\t0.698\t0.337\n",
            "Number of parameter: 77.49M\n",
            "Number of parameter: 77.61M\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.\n",
            "  6% 87/1500 [00:00<00:13, 108.67it/s]T2S Decoding EOS [184 -> 278]\n",
            "  6% 93/1500 [00:00<00:13, 104.04it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.265\t0.043\t0.901\t0.380\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 我爱袁永宽，赵兰是大坏蛋。赵兰是大坏蛋。赵兰是大坏蛋。\n",
            "Actual Input Target Text (after sentence segmentation): 我爱袁永宽，赵兰是大坏蛋。赵兰是大坏蛋。赵兰是大坏蛋。\n",
            "Actual Input Target Text (per sentence): 我爱袁永宽，赵兰是大坏蛋。赵兰是大坏蛋。赵兰是大坏蛋。\n",
            "Processed text from the frontend (per sentence): 我爱袁永宽,赵兰是大坏蛋.赵兰是大坏蛋.赵兰是大坏蛋.\n",
            " 14% 203/1500 [00:01<00:11, 112.87it/s]T2S Decoding EOS [184 -> 391]\n",
            " 14% 206/1500 [00:01<00:11, 111.48it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.198\t0.046\t1.850\t0.392\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Actual Input Reference Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text: 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text (after sentence segmentation): 喂，张老师。我们这边是朗培教育的售后。\n",
            "Actual Input Target Text (per sentence): 喂，张老师。我们这边是朗培教育的售后。\n",
            "Processed text from the frontend (per sentence): 喂,张老师.我们这边是朗培教育的售后.\n",
            "  9% 128/1500 [00:01<00:18, 72.23it/s]T2S Decoding EOS [184 -> 315]\n",
            "  9% 130/1500 [00:01<00:18, 75.43it/s]\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "0.277\t0.057\t1.727\t0.543\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/blocks.py\", line 2400, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/GPT-SoVITS/webui.py\", line 1048, in <module>\n",
            "    app.queue().launch(#concurrency_count=511, max_size=1022\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/blocks.py\", line 2307, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/blocks.py\", line 2404, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.9/site-packages/gradio/http_server.py\", line 68, in close\n",
            "    self.thread.join()\n",
            "  File \"/usr/local/lib/python3.9/threading.py\", line 1060, in join\n",
            "    self._wait_for_tstate_lock()\n",
            "  File \"/usr/local/lib/python3.9/threading.py\", line 1080, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 0.0.0.0:9874 <> https://7c262db2e2c53b61ab.gradio.live\n",
            "^C\n"
          ]
        }
      ]
    }
  ]
}